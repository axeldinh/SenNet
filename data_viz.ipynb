{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Magics for the Jupyter notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data_path = \"C:/Users/Axeld/Desktop/SenNet/blood-vessel-segmentation/train/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from utils.mesh import make_mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Meshes of the Vasculatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2279 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2279/2279 [00:58<00:00, 39.06it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for min_area in [0, 20, 50, 100, 200]:\n",
    "    for dataset in os.listdir(data_path):\n",
    "        dataset_path = os.path.join(data_path, dataset)\n",
    "        if \"labels\" not in os.listdir(dataset_path):\n",
    "            continue\n",
    "        if \"voi\" in dataset:\n",
    "            continue\n",
    "        masks_path = os.path.join(data_path, dataset, \"labels\")\n",
    "\n",
    "        os.makedirs(\"meshes\", exist_ok=True)\n",
    "\n",
    "        #if os.path.exists(f\"meshes/{dataset}_area{min_area}.obj\"):\n",
    "        #    continue\n",
    "\n",
    "        f = open(f\"meshes/{dataset}_area{min_area}.obj\", \"w\")\n",
    "\n",
    "        make_mesh(masks_path, min_area, f\"meshes/{dataset}_area{min_area}.obj\")\n",
    "        break\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a video of the volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2279 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2279/2279 [00:58<00:00, 38.75it/s]\n",
      "100%|██████████| 2217/2217 [01:09<00:00, 32.06it/s]\n",
      "100%|██████████| 1035/1035 [00:53<00:00, 19.31it/s]\n"
     ]
    }
   ],
   "source": [
    "scale = 2\n",
    "for dataset in os.listdir(data_path):\n",
    "    dataset_path = os.path.join(data_path, dataset)\n",
    "    if \"labels\" not in os.listdir(dataset_path):\n",
    "        continue\n",
    "    if \"images\" not in os.listdir(dataset_path):\n",
    "        continue\n",
    "    if \"voi\" in dataset:\n",
    "        continue\n",
    "    images_path = os.path.join(data_path, dataset, \"images\")\n",
    "    masks_path = os.path.join(data_path, dataset, \"labels\")\n",
    "\n",
    "    files = os.listdir(masks_path)\n",
    "    files.sort(key=lambda x: int(x.split(\".\")[0]))\n",
    "\n",
    "    video = None\n",
    "\n",
    "    for file in tqdm(files):\n",
    "\n",
    "        i = int(file.split(\".\")[0])\n",
    "\n",
    "        if i % scale != 0:\n",
    "            continue\n",
    "        \n",
    "        img = cv2.imread(os.path.join(images_path, file), cv2.IMREAD_GRAYSCALE)\n",
    "        mask = cv2.imread(os.path.join(masks_path, file), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        img = cv2.equalizeHist(img)\n",
    "        \n",
    "        # Decrease the resolution\n",
    "        img = cv2.resize(img, (img.shape[0] // scale, img.shape[1] // scale), interpolation=cv2.INTER_NEAREST)\n",
    "        mask = cv2.resize(mask, (mask.shape[0] // scale, mask.shape[1] // scale), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "        mask = np.concatenate([mask[:, :, None], mask[:, :, None], mask[:, :, None]], axis=2)\n",
    "        \n",
    "        # Make a red mask\n",
    "        mask[:, :, 0] = 0\n",
    "        mask[:, :, 1] = 0\n",
    "\n",
    "        overlay = cv2.addWeighted(img, 0.5, mask, 0.5, 0)\n",
    "\n",
    "        encoding = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        if video is None:\n",
    "            video = cv2.VideoWriter(f\"{dataset}.mp4\", encoding, 10, (img.shape[1], img.shape[0]))\n",
    "\n",
    "        video.write(overlay)\n",
    "\n",
    "    video.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
